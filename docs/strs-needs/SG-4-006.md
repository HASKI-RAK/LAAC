# SG-4-006 — Developers

- Stakeholder Group: Developers
- Need: New learning analytics metrics can be added quickly through a clear, extensible pipeline from LRS data access to exposed API.
- Rationale: Developers must react fast to new requirements and research needs by adding metrics with minimal friction.
- Outcome: A streamlined, documented process and stable extension points allow adding a metric with predictable steps and limited code touch points.
- Acceptance Criteria:
  - Clear architecture/extension points (e.g., `Metric` interface/contract, registry/factory, module bound to NestJS DI).
  - Contribution guide documents the step-by-step process to add a metric (data access, compute, tests, API wiring, docs).
  - Scaffolding/template or example provided to create a new metric consistently.
  - Tests required for each new metric (unit + e2e path to API).
  - Lead time target defined (e.g., a simple metric added in ≤ 1 day including tests and docs) and validated on at least one example metric.
- Priority: High
- Assumptions: Metrics depend only on xAPI/LRS data and shared utilities; public API and OpenAPI docs are generated from source annotations; module boundaries follow NestJS conventions.

